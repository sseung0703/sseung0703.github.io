---
layout: post
title: "2020_3rd_quarter"
date: 2020-07-02
image_url: https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG
mathjax: true
comments: true
---

# Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks
## Zhonghui You, Kun Yan, Jinmian Ye, Meng Ma, Ping Wang, NeurIPS 2019
### 발표자: 이승현 [[paper link](https://arxiv.org/abs/1909.08174), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f3a18b1378bf75d14551518/d9d8f8016b1e58e1877fc6a43b1cd812/GDP.pdf)]
- Filter pruning 기법 중 하나로 기존 기법에 비해 효과적으로 filter의 importance를 정의하고, 이를 기반으로 filter를 제거 및 pruned network를 tuning할 수 있는 방법을 제안한 논문입니다.
- Gate decorator란 Taylor expansion에 기반한 기법으로, pruning할 각 layer에 gate vector를 추가 및 이의 gradient에 기반한 score를 정하며 이는 아래와 같습니다.

$$\Theta(\phi_i) = \sum_{(X, Y) \in \mathcal D}\left| \frac{\delta \mathcal{L}(X,Y;\theta)}{\delta \phi_i} \phi_i \right| $$

- Tick step에서는 gate를 tuning 및 일정 비율을 pruning하며, Tock step에서는 손실된 성능을 복원하기 위해 일정 epoch만큼 fine-tuning 합니다. 이 때 Tock step에서는 gate에 $$L_1$$-regularization을 가해 sparce해지도록 만듭니다.
- Pruning 시에 network의 특성에 따라 서로 종속적인 layer들을 group으로 묶어 하나의 gate를 통해 importance score를 계산 및 동시에 pruning되도록 합니다.
- 높은 성능을 보이며 몇 가지 중요한 insight를 주는 좋은 기법으로 보이지만, pruning 시간이 매우 길다는 것은 큰 단점으로 보입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/26036843/90788752-14d36880-e341-11ea-829e-2485ce943e91.png">
  <img src="https://user-images.githubusercontent.com/26036843/90788498-d63dae00-e340-11ea-87b5-7a0f37c1d93a.png">
</p>


# Data-Efficient Hierarchical Reinforcement Learning (HIRO)
## Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine
### 발표자: 주동욱 [[paper link](https://arxiv.org/abs/1805.08296), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f433e7cd7804e0c251f6146/0f5d11f0886ebead360e5b1119f652ea/HIRO_%EC%A3%BC%EB%8F%99%EC%9A%B1.pdf)]
- Task Hierarchy가 복잡한 Continuous Action Space 환경에서 Generally Applicable Off-Policy HRL 알고리즘을 제안하였습니다.
- 기존의 HRL은 higher-level policy를 최적화하는 과정에서 non-stationary problem으로 인하여 On-Policy 방식으로 업데이트를 하여 Sample Efficiency가 떨어지는 단점이 있었지만, 본 논문에서는 Off-Policy Correction을 통하여 이를 해결한 Off-Policy 알고리즘을 제안하였습니다.
- 단점으로는 HRL 이 모두 그렇지만 Task 의 Hierarchical Structure 가 명확하지 않을 때는 쓰기 어렵습니다. 반대로 Locomotive Task 계열에서는 자연스럽게 적용 가능할 것으로 보입니다.
- General HRL Algorithm 중에서 비교적 초기의(2018) 논문이므로 이어질 이후 이어지는 연구 동향을 살펴보면 좋을 것 같습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/32321592/91457593-79517300-e8bf-11ea-865b-57d44c1464ac.PNG">
  <img src="https://user-images.githubusercontent.com/32321592/91457597-7a82a000-e8bf-11ea-9d1c-aabe88d567ad.PNG">
</p>


# wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
## Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli
### 발표자: 김성빈 [[paper link](https://arxiv.org/pdf/2006.11477.pdf), [presentation material](https://trello-attachments.s3.amazonaws.com/5d15b7297b29f54b88064f86/5f1aad71ab3a130c1e0525f1/af29044c08c46289dc504ada199cebe5/wav2vec2_presentation_%EC%88%98%EC%A0%95.pdf)]
- 비교적 구하기 쉬운 Unlabeled 음성데이터를 통해 General한 Representation을 배우는 Self-Supervised 기법을 제시
- 10분의 labeled 음성만으로도 사용 가능한 수준의 성능을 지닌 음성인식모델을 학습할 수 있음
<p align="center">
  <img src="https://user-images.githubusercontent.com/25909311/92239225-9b697780-eef5-11ea-8cab-60c9ec24ca90.png">
</p>

- 비슷한 방법으로 기존에 vq-wav2vec이 존재했지만 Quantization을 한 후에 Bert학습을 하는 two-step으로 구성되어있고 Qunatization을 하면서 정보가 손실되는 단점이 있었음
- wav2vec2.0은 Continuos한 input으로 학습을 하고 two-step을 End-to-End로 학습 할 수 있는 방법을 제시함으로서 성능을 개선하였음
- 데이터셋이 거의 없는 언어에 대해서도 음성인식모델 구축을 가능하게 할 수 있는 가능성을 제시함으로써 Self-supervised 음성인식에 크게 의미있는 연구라고 생각됨
